
\فصل{مفاهیم اولیه}\label{فصل۲:مفاهیم اولیه}

\قسمت{شبکه عصبی \lr{CNN}}
شبکه‌های عصبی پیچشی (\lr{Convolutional Neural Networks} یا \lr{CNN}) نوعی از شبکه‌های عصبی مصنوعی هستند که به طور خاص برای پردازش داده‌های با ساختار شبکه‌ای مانند تصاویر طراحی شده‌اند. این شبکه‌ها به دلیل توانایی بالای خود در شناسایی الگوها و ویژگی‌ها، به طور گسترده در مسائلی مانند طبقه‌بندی تصاویر \پانویس{\lr{Image Classification}} و تشخیص اشیاء\پانویس{\lr{Object Detection}} استفاده می‌شوند. \lr{CNN‌}ها از معماری سلسله‌مراتبی\پانویس{\lr{Hierarchical}} برای استخراج ویژگی‌ها از داده‌های ورودی استفاده می‌کنند و قادرند ویژگی‌های سطح پایین (مانند لبه‌ها) تا ویژگی‌های سطح بالا (مانند اشکال پیچیده) را به طور خودکار شناسایی کنند.



\شروع{شکل}[ht]
\centerimg{img2}{14cm}
\شرح{ساختار یک شبکه \lr{CNN} \مرجع{convolutional_neural_network}}
\برچسب{شکل:ساختار یک CNN}
\پایان{شکل}



\قسمت{اجزای اصلی شبکه \lr{CNN}}

\زیرقسمت{لایه کانولوشن: }
این لایه وظیفه استخراج ویژگی‌ها از داده‌های ورودی را بر عهده دارد. در این لایه، یک یا چند فیلتر\پانویس{\lr{Kernel}} کوچک بر روی داده‌های ورودی حرکت کرده و عملیات کانولوشن را انجام می‌دهند. نتیجه این عملیات ویژگی‌های مکانی\پانویس{\lr{Spatial Features}} است که اطلاعات مهم را حفظ کرده و داده‌های غیرضروری را حذف می‌کند.


\شروع{شکل}[ht]
\centerimg{img3}{14cm}
\شرح{عملیات کانولوشن \مرجع{cnn_introduction}}
\برچسب{شکل:عملیات کانولوشن}
\پایان{شکل}





\زیرقسمت{لایه فعال‌سازی: }
پس از هر لایه کانولوشن، از یک تابع فعال‌ساز\پانویس{\lr{Activation Function}} غیرخطی (مانند \texttt{ReLU})\پانویس{\lr{Rectified Linear Unit}} استفاده می‌شود. این تابع باعث می‌شود مدل بتواند روابط پیچیده و غیرخطی را یاد بگیرد. تابع \texttt{ReLU} معمولاً بیشترین استفاده را دارد و با نگه‌داشتن مقادیر مثبت و صفر کردن مقادیر منفی، سرعت و کارایی مدل را افزایش می‌دهد.

\شروع{شکل}[ht]
\centerimg{img4}{16cm}
\شرح{تابع فعال‌ساز \texttt{ReLU} \مرجع{cnn_relu_layer}}
\برچسب{شکل:تابع فعالساز رلو}
\پایان{شکل}



\زیرقسمت{لایه تجمیع: }
لایه تجمیع\پانویس{\lr{Pooling}} وظیفه کاهش ابعاد داده‌ها را دارد تا تعداد پارامترها و پیچیدگی محاسباتی کاهش یابد. معمولاً از روش \lr{Max Pooling} استفاده می‌شود، که در آن بزرگ‌ترین مقدار در هر ناحیه انتخاب می‌شود. این فرآیند باعث افزایش مقاومت مدل در برابر تغییرات جزئی در داده‌های ورودی (مانند انتقال یا چرخش) می‌شود.


\شروع{شکل}[ht]
\centerimg{img5}{11cm}
\شرح{لایه \texttt{Max\_pooling} \مرجع{max_pooling}}
\برچسب{شکل:لایه مکس پولینگ}
\پایان{شکل}



\زیرقسمت{لایه تمام‌متصل: }
لایه تمام‌متصل\پانویس{\lr{Fully Connected}}، ویژگی‌های استخراج‌شده توسط لایه‌های قبلی را به صورت یک بردار مسطح درمی‌آیند و به نرون‌های خروجی متصل می‌شوند. این لایه وظیفه تصمیم‌گیری نهایی (مانند طبقه‌بندی) را بر عهده دارد.

\شروع{شکل}[ht]
\centerimg{img6}{11cm}
\شرح{لایه تمام‌متصل \مرجع{cnn_complete_guide}}
\برچسب{شکل:لایه تمام متصل}
\پایان{شکل}



\زیرقسمت{لایه خروجی: }
این لایه از یک تابع فعال‌سازی مانند \lr{Softmax} یا \lr{Sigmoid} برای تولید خروجی استفاده می‌کند. خروجی این لایه معمولاً احتمال تعلق ورودی به هر کلاس در مسئله طبقه‌بندی است.





\قسمت{نحوه عملکرد شبکه \lr{CNN}}
\lr{CNN}ها
با دریافت داده‌های ورودی (مانند تصاویر)، آن‌ها را از طریق لایه‌های مختلف عبور داده و ویژگی‌های مهم را مرحله به مرحله استخراج می‌کنند. در هر مرحله، ویژگی‌ها پیچیده‌تر و خاص‌تر می‌شوند. لایه‌های کانولوشنی ویژگی‌ها را استخراج می‌کنند، لایه‌های تجمیع ابعاد داده‌ها را کاهش می‌دهند و در نهایت، لایه‌های تمام‌متصل و خروجی تصمیم‌گیری نهایی را انجام می‌دهند. این معماری به \lr{CNN}‌ها اجازه می‌دهد تا در کاربردهایی مانند شناسایی چهره، تشخیص اشیاء و تحلیل تصاویر پزشکی عملکردی بسیار دقیق و مؤثر داشته باشند.





\قسمت{ساختار FPGA}





\قسمت{ابزار HLS}