
\فصل{مفاهیم اولیه}\label{فصل۲:مفاهیم اولیه}

\قسمت{شبکه عصبی \lr{CNN}}
شبکه‌های عصبی پیچشی (\lr{Convolutional Neural Networks} یا \lr{CNN}) نوعی از شبکه‌های عصبی مصنوعی هستند که به طور خاص برای پردازش داده‌های با ساختار شبکه‌ای مانند تصاویر طراحی شده‌اند. این شبکه‌ها به دلیل توانایی بالای خود در شناسایی الگوها و ویژگی‌ها، به طور گسترده در مسائلی مانند طبقه‌بندی تصاویر \پانویس{\lr{Image Classification}} و تشخیص اشیاء\پانویس{\lr{Object Detection}} استفاده می‌شوند. \lr{CNN‌}ها از معماری سلسله‌مراتبی\پانویس{\lr{Hierarchical}} برای استخراج ویژگی‌ها از داده‌های ورودی استفاده می‌کنند و قادرند ویژگی‌های سطح پایین (مانند لبه‌ها) تا ویژگی‌های سطح بالا (مانند اشکال پیچیده) را به طور خودکار شناسایی کنند.



\شروع{شکل}[ht]
\centerimg{img2}{14cm}
\شرح{ساختار یک شبکه \lr{CNN} \مرجع{convolutional_neural_network}}
\برچسب{شکل:ساختار یک CNN}
\پایان{شکل}



\قسمت{اجزای اصلی شبکه \lr{CNN}}

\زیرقسمت{لایه کانولوشن}
این لایه وظیفه استخراج ویژگی‌ها از داده‌های ورودی را بر عهده دارد. در این لایه، یک یا چند فیلتر\پانویس{\lr{Kernel}} کوچک بر روی داده‌های ورودی حرکت کرده و عملیات کانولوشن را انجام می‌دهند. نتیجه این عملیات ویژگی‌های مکانی\پانویس{\lr{Spatial Features}} است که اطلاعات مهم را حفظ کرده و داده‌های غیرضروری را حذف می‌کند.


\شروع{شکل}[ht]
\centerimg{img3}{14cm}
\شرح{عملیات کانولوشن \مرجع{cnn_introduction}}
\برچسب{شکل:عملیات کانولوشن}
\پایان{شکل}





\زیرقسمت{لایه فعال‌سازی}
پس از هر لایه کانولوشن، از یک تابع فعال‌ساز\پانویس{\lr{Activation Function}} غیرخطی (مانند \texttt{ReLU})\پانویس{\lr{Rectified Linear Unit}} استفاده می‌شود. این تابع باعث می‌شود مدل بتواند روابط پیچیده و غیرخطی را یاد بگیرد. تابع \texttt{ReLU} معمولاً بیشترین استفاده را دارد و با نگه‌داشتن مقادیر مثبت و صفر کردن مقادیر منفی، سرعت و کارایی مدل را افزایش می‌دهد.

\شروع{شکل}[ht]
\centerimg{img4}{16cm}
\شرح{تابع فعال‌ساز \texttt{ReLU} \مرجع{cnn_relu_layer}}
\برچسب{شکل:تابع فعالساز رلو}
\پایان{شکل}



\زیرقسمت{لایه تجمیع}
لایه تجمیع\پانویس{\lr{Pooling}} وظیفه کاهش ابعاد داده‌ها را دارد تا تعداد پارامترها و پیچیدگی محاسباتی کاهش یابد. معمولاً از روش \lr{Max Pooling} استفاده می‌شود، که در آن بزرگ‌ترین مقدار در هر ناحیه انتخاب می‌شود. این فرآیند باعث افزایش مقاومت مدل در برابر تغییرات جزئی در داده‌های ورودی (مانند انتقال یا چرخش) می‌شود.


\شروع{شکل}[ht]
\centerimg{img5}{11cm}
\شرح{لایه \texttt{Max\_pooling} \مرجع{max_pooling}}
\برچسب{شکل:لایه مکس پولینگ}
\پایان{شکل}



\زیرقسمت{لایه تمام‌متصل}
لایه تمام‌متصل\پانویس{\lr{Fully Connected}}، ویژگی‌های استخراج‌شده توسط لایه‌های قبلی را به صورت یک بردار مسطح درمی‌آیند و به نرون‌های خروجی متصل می‌شوند. این لایه وظیفه تصمیم‌گیری نهایی (مانند طبقه‌بندی) را بر عهده دارد.

\شروع{شکل}[ht]
\centerimg{img6}{11cm}
\شرح{لایه تمام‌متصل \مرجع{cnn_complete_guide}}
\برچسب{شکل:لایه تمام متصل}
\پایان{شکل}


\زیرقسمت{لایه خروجی}
این لایه از یک تابع فعال‌سازی مانند \lr{Softmax} یا \lr{Sigmoid} برای تولید خروجی استفاده می‌کند. خروجی این لایه معمولاً احتمال تعلق ورودی به هر کلاس در مسئله طبقه‌بندی است.





\قسمت{نحوه عملکرد شبکه \lr{CNN}}
\lr{CNN}ها
با دریافت داده‌های ورودی (مانند تصاویر)، آن‌ها را از طریق لایه‌های مختلف عبور داده و ویژگی‌های مهم را مرحله به مرحله استخراج می‌کنند. در هر مرحله، ویژگی‌ها پیچیده‌تر و خاص‌تر می‌شوند. لایه‌های کانولوشنی ویژگی‌ها را استخراج می‌کنند، لایه‌های تجمیع ابعاد داده‌ها را کاهش می‌دهند و در نهایت، لایه‌های تمام‌متصل و خروجی تصمیم‌گیری نهایی را انجام می‌دهند. این معماری به \lr{CNN}‌ها اجازه می‌دهد تا در کاربردهایی مانند شناسایی چهره، تشخیص اشیاء و تحلیل تصاویر پزشکی عملکردی بسیار دقیق و مؤثر داشته باشند.





\قسمت{ساختار FPGA}
\lr{FPGA}\پانویس{\lr{Field-Programmable Gate Array}}
یک تراشه سخت‌افزاری قابل‌برنامه‌ریزی است که به کاربران اجازه می‌دهد ساختار داخلی آن را پس از تولید تغییر دهند و برای کاربردهای خاص طراحی کنند. این قابلیت بازپیکربندی\پانویس{\lr{Reconfigurable}} یکی از ویژگی‌های کلیدی \lr{FPGA} است که امکان اجرای مجموعه‌ای از عملکردهای منطقی و موازی را با انعطاف‌پذیری بالا فراهم می‌کند. \lr{FPGA}‌ها از ساختارهایی شامل بلوک‌های منطقی قابل‌پیکربندی (\lr{CLB})\پانویس{\lr{Combinational Logic Block}}، منابع اتصالات قابل‌برنامه‌ریزی، و منابع ورودی/خروجی تشکیل شده‌اند که با یکدیگر کار می‌کنند تا مدارهای دلخواه را پیاده‌سازی کنند.



\قسمت{اجزای مهم FPGA}

\زیرقسمت{بلوک‌های منطقی قابل‌پیکربندی (\lr{CLB})}
این بلوک‌ها هسته اصلی \lr{FPGA} هستند و از ترکیب \lr{LUT}، فلیپ‌فلاپ‌ها، و عناصر منطقی تشکیل شده‌اند. \lr{LUT‌}ها امکان پیاده‌سازی توابع منطقی را فراهم می‌کنند و فلیپ‌فلاپ‌ها برای ذخیره مقادیر استفاده می‌شوند. با استفاده از \lr{CLB}ها، می‌توان انواع گیت‌های منطقی و توابع پیچیده‌تر را پیاده‌سازی کرد.

\شروع{شکل}[ht]
\centerimg{img7}{11cm}
\شرح{\lr{CLB} ها در \lr{FPGA}}
\برچسب{شکل:سی‌ال‌بی در اف‌پی‌جی‌ای}
\پایان{شکل}


\زیرقسمت{منابع اتصالات (\lr{Routing Resources})}
\lr{FPGA}
دارای شبکه‌ای از مسیرهای قابل‌برنامه‌ریزی است که بلوک‌های منطقی را به یکدیگر و به پورت‌های ورودی/خروجی متصل می‌کند. این منابع شامل سوئیچ‌ها و ماتریس‌های اتصالات است که امکان تنظیم مسیرهای داده در \lr{FPGA} را فراهم می‌کنند.

\زیرقسمت{بلوک‌های ورودی/خروجی (\lr{I/O Blocks})}
این بلوک‌ها مسئول ارتباط \lr{FPGA} با دنیای خارجی هستند و امکان تبادل داده با سایر دستگاه‌ها را فراهم می‌کنند. \lr{I/O}ها برای پشتیبانی از پروتکل‌های مختلف ارتباطی قابل‌پیکربندی هستند.


\زیرقسمت{حافظه‌های داخلی}
\lr{FPGA}ها
شامل حافظه‌هایی مانند \lr{RAM} بلوکی\پانویس{\lr{BRAM}} و حافظه‌های توزیع‌شده\پانویس{\lr{Distributed RAM}} هستند که برای ذخیره داده‌ها و متغیرها در طول اجرای عملیات استفاده می‌شوند.


\زیرقسمت{واحد‌های \lr{DSP}}
اکثر \lr{FPGA‌}های مدرن دارای واحدهای پردازش سیگنال دیجیتال\پانویس{\lr{DSP}} هستند که برای عملیات ریاضی پیچیده مانند ضرب و جمع بهینه‌سازی شده‌اند. این واحدها نقش مهمی در کاربردهایی مانند پردازش سیگنال و یادگیری عمیق ایفا می‌کنند.


\قسمت{قابلیت بازپیکربندی \lr{FPGA}}
\lr{FPGA}ها
به کاربران اجازه می‌دهند مدار داخلی خود را با استفاده از ابزارهای سنتز سخت‌افزاری مانند \lr{Verilog}، \lr{VHDL}، یا \lr{HLS} تغییر دهند. این قابلیت به معنای انعطاف‌پذیری بالا برای تغییر یا بهبود طراحی است، حتی پس از ساخت سخت‌افزار. علاوه بر این، برخی از \lr{FPGA}ها از بازپیکربندی پویا\پانویس{\lr{Dynamic Reconfiguration}} پشتیبانی می‌کنند که امکان تغییر بخشی از طراحی را در زمان اجرا بدون اختلال در عملکرد سایر بخش‌ها فراهم می‌کند.


\قسمت{ابزار HLS}
\lr{Xilinx Vitis HLS (High-Level Synthesis)}
یک پلتفرم توسعه نرم‌افزاری است که به مهندسان این امکان را می‌دهد تا کدهای نرم‌افزاری نوشته شده در زبان‌های سطح بالا مانند \lr{C}، \lr{C++} یا \lr{OpenCL} را به سخت‌افزار \lr{FPGA} تبدیل کنند. هدف اصلی این ابزار تسهیل فرآیند طراحی سخت‌افزار است، به‌گونه‌ای که توسعه‌دهندگان نیازی به درک عمیق از جزئیات معماری \lr{FPGA} نداشته باشند. با استفاده از \lr{Vitis HLS}، طراحی‌های سخت‌افزاری به طور خودکار از کدهای سطح بالا استخراج شده و به طراحی‌های RTL\پانویس{\lr{Register-Transfer Level}} که قابل‌سنتز در \lr{FPGA} هستند، تبدیل می‌شوند.


\زیرقسمت{مزایای استفاده از \lr{Xilinx Vitis HLS}}

\شروع{فقرات}

\فقره \مهم{کاهش زمان توسعه}
استفاده از زبان‌های سطح بالا برای نوشتن کد، به طراحان این امکان را می‌دهد که زمان بیشتری برای الگوریتم‌ها و منطق طراحی صرف کنند و به‌جای پرداختن به جزئیات معماری \lr{FPGA}، تمرکز بیشتری بر روی ویژگی‌های عملکردی داشته باشند.

\فقره \مهم{ارتقاء عملکرد}
ابزار \lr{Vitis HLS} این امکان را فراهم می‌کند که طراحی‌های سخت‌افزاری بهینه‌سازی شوند، به‌ویژه در زمینه‌هایی مانند پردازش موازی، سرعت بالا و کارایی انرژی.

\فقره \مهم{سادگی پیاده‌سازی}
بدون نیاز به دانش تخصصی در زمینه زبان‌های سخت‌افزاری مانند \lr{VHDL} یا \lr{Verilog}، مهندسان می‌توانند به راحتی از\lr{ C/C++} یا \lr{OpenCL} برای ایجاد مدارهای پیچیده استفاده کنند.
\پایان{فقرات}

