
\فصل{مقاله \مرجع{article1}}



\قسمت{ایده اصلی مقاله}
در این مقاله، به مسئله Placement با رویکرد یک مسئله شبکه عصبی نگاه شده است و تلاش شده است که بهینه ترین حالت ممکن پیدا شود. خروجی این مقاله منجر به ارائه یک چارچوب\پاورقی{Framework} متن باز\پاورقی{Open Source} مبتنی بر CPU و GPU با استفاده از شبکه‌های عمیق و زبان برنامه نویسی \texttt{Python} و \texttt{C++} و کتابخانه های \texttt{PyTorch} و \texttt{CUDA} شده است که بدون افت کیفیت نسبیت به روش‌های قدیمی، تا \textbf{۳۰ برابر} افزایش سرعت برای مسئله چینش ارائه شده است.





\قسمت{کار‌های پیشین}
روش ها و الگوریتم هایی که تا اکنون توسعه داده شده است، به نام پیاده‌سازی تحلیلی\پاورقی{Analytical placement} معروف است. این روش ها خروجی‌های با کیفیتی تولید می‌کنند اما مشکل عمده این روش ها، کند بودن آنهاست. معمولا برای افزایش سرعت در این روش ها از تکنیک‌های چند‌نخی\پاورقی{Multi-thread} کردن CPU استفاده می‌شود. روش‌های مبتنی بر چند‌نخی، سرعت جایگذاری را تا ۵ برابر افزایش می‌دهند اما مشکل عمده آنها این است که کیفیت طرح خروجی، بین ۲ الی ۶ درصد کاهش می‌یابد. \مرجع{article3, article4, article5}

یعنی الگوریتم‌های توسعه داده شده مبتنی بر چند نخی، صرفا از جهت افزایش سرعت بهینه کار می‌کنند و توجه اصلی بر روی افزایش سرعت است. اما توجهی کمتری نسبت به بهبود کیفیت خروجی دارند و همین امر موجب نا کار‌امد بودن چنین الگوریتم‌هایی می‌شود.

دسته دیگری از الگوریتم‌ها بر بستر GPU توسعه داده شده است.\مرجع{article6} این الگوریتم بر اساس خوشه‌بندی\پاورقی{Clustering} انجام شده است که با موازی‌سازی بر بستر GPU، به‌طور میانگین، سرعت تا ۱۵ برابر نسبت به روش Analytical افزایش یافته است. درصد افت کیفیت نیز برای این الگوریتم، کمتر از ۱ درصد گزارش شده است. اما این روش نیز به دلیل هزینه بالا برای فراهم کردن GPU مورد اقبال واقع نشده است. \مرجع{article7}

در این مقاله روشی که توسعه داده شده است، بر مبنای روش‌های تحلیلی نام برده شده است. با این تفاوت که این الگوریتم هم در بستر GPU و هم در بستر CPU شتابدهی شده است. که از این بابت عام منظوره بودن الگوریتم و هزینه پایین آن نسبت به سایر الگوریتم های موجود را نشان می‌دهد.

این الگوریتم که به نام DREAM-Place نام‌گذاری شده است، به صورت عمومی\پاورقی{Generic} توسعه داده شده است که با سایر الگوریتم‌های جای‌گذاری تحلیلی مثل NTUplace سازگار است. \مرجع{article8}

ایده‌های اصلی\پاورقی{Contributions} مقاله به صورت زیر عنوان شده است:
\شروع{فقرات}
\فقره ایجاد دیدگاهی کاملا جدید برای ارتباط دنیای طراحی آیسی با دنیای هوش‌مصنوعی و یادگیری عمیق به صورت کاملا متن باز برای توسعه در CPU و GPU
\فقره محاسبه بهترین محل قرار گیری سلول ها با کمترین طول و چگالی سیم.
\فقره بهبود سرعت چینش بدون افت کیفیت خروجی تا ۳۰ برابر. به طوری که طراحی ای با ۱ میلیون سلول در بستر CPU در یک دقیقه تمام می‌شود. که این تایمینگ به صورت خطی با افزایش تعداد سلول ها تا حداکثر ۱۰ میلیون تغییر می‌کند.
\پایان{فقرات}


تمام سورس‌کد نوشته شده برای این الگ.ریتم نیز در گیت‌هاب\زیرنویس{\href{https://github.com/limbo018/DREAMPlace}{\lr{github.com/limbo018/DREAMPlace}}} قابل دریافت است.



\قسمت{مراحل انجام الگوریتم}
قبل از بررسی مراحل انجام، نیاز است که برخی از اصطلاحات این حوزه را بیان کنیم.

جاگذاری تحلیلی\پاورقی{Analytical placement} دارای ۳ مرحله اصلی است:

\شروع{فقرات}
\فقره چینش کلی یا GP\پاورقی{Global Placement}: قرار دادن سلول‌ها در طرح با هدف بهینه شدن GP و مینیمم Routing
\فقره بررسی قوانین یا LG\پاورقی{Legalization}: بررسی طراحی انجام شده در مرحله GP و حذف همپوشانی ها و تراز کردن مشکلات طرح.
\فقره چینش جزئی یا DP\پاورقی{Detailed Placement}: بررسی دقیق تر طراحی انجام شده برای رسیدن به دقت و کیفیت بالا در طراحی.
\پایان{فقرات}

\مهم{معمولا مرحله GP بیشترین زمان را در فرایند صرف می‌کند به همین دلیل، تمام الگوریتم‌های بیان شده در قبل و همچنین این الگوریتم، نتایج مورد بحث، در مورد مینیمم کردن طول مسیر ها و چگالی آنهاست.}

مراحل انجام این الگوریتم را می‌توان به صورت زیر بیان کرد:
\شروع{شکل}[ht]
\centerimg{img1_DREAMPlace2_flow.png}{12cm}
\شرح{ساختار الگوریتم}
\برچسب{شکل:ساختار الگوریتم}
\پایان{شکل}

در ایتدا و در مهمترین فاز، ورودی‌ها که شامل محل قرار گیری سلول هاست، به شبکه داده می‌شود و شبکه که در ابتدا به یک سری وزن های رندوم مقدار دهی شده است، آموزش می‌بیند و خروجی آن که مقدار خطای محاسبه شده است، با استفاده از الگوریتم پس انتشار خطا\پاورقی{Back Propagation} به لایه های عقب تر انتشار داده می‌شود تا اینکه بهینه ترین خطا (مینیمم ترین حالا خطا) را پیدا کنیم. «شکل \رجوع{شکل:فرایند آموزش وزن‌های اولیه}»



مراحل انجام این الگوریتم را می‌توان به صورت زیر بیان کرد:
\شروع{شکل}[ht]
\centerimg{img1_trainW.png}{8cm}
\شرح{فرایند آموزش شبکه برای پیدا کردن وزن‌های اولیه}
\برچسب{شکل:فرایند آموزش وزن‌های اولیه}
\پایان{شکل}




پس از پیدا کردن خطای مینیمم، وزن های آموزش دیده شده در آن خطا، به عنوان وزن های شبکه ما برای آموزش شبکه شبکه، برای حل مسئله چینش انتخاب می‌شوند و در فاز دوم آموزش، گره ها یه عنوان ورودی به شبکه از پیش آموزش دیده شده با وزن‌های مشخص داده می‌شود و با استفاده از همان الگوریتم پس‌انتشار خطا، فرایند آموزش تا زمان مینیمم شدن خطا ادامه پیدا می‌کند. «شکل \رجوع{شکل:فرایند آموزش شبکه برای پیدا کردن بهترین چینش}»


مراحل انجام این الگوریتم را می‌توان به صورت زیر بیان کرد:
\شروع{شکل}[ht]
\centerimg{img2_trainNet.png}{8cm}
\شرح{فرایند آموزش شبکه برای پیدا کردن بهترین چینش}
\برچسب{شکل:فرایند آموزش شبکه برای پیدا کردن بهترین چینش}
\پایان{شکل}


برای پیدا کردن خطا هم به سادگی تابع $f(y,\hat{y})=|\hat{y}-y|)$ محاسبه شده است که در این رابطه $\hat{y}$ مقدار بدست آمده توسط شبکه است که در «شکل \رجوع{شکل:فرایند آموزش وزن‌های اولیه}» با $\phi(x_i;w)$ نشان داده شده است.

در ادامه، نمودار زمانی بخش‌های مختلف الگوریتم مانند GP و LG و ... این الگوریتم در بستر CPU در دو حالت تک نخی و ۱۰ نخی برای طراحی \texttt{bigblue4}\زیرنویس{این طراحی متشکل از ۲ میلیون سلول است} در «شکل \رجوع{شکل:نمودار زمانی شبکه آموزش دیده شده در بستر CPU}» آورده شده است:

\شروع{شکل}[ht]
\centerimg{img3_output_circular.png}{10cm}
\شرح{نمودار زمانی شبکه آموزش دیده شده در بستر CPU}
\برچسب{شکل:نمودار زمانی شبکه آموزش دیده شده در بستر CPU}
\پایان{شکل}




\شروع{شکل}[ht]
\centerimg{img4.png}{12cm}
\شرح{خروجی واقعی شبکه برای مسئله چینش}
\برچسب{شکل:خروجی واقعی شبکه برای مسئله چینش}
\پایان{شکل}



همانطور که انتظار می‌رفت، با افزایش تعداد نخ ها در CPU زمان انجام بخش‌های مختلف کاهش یافته است. برای نمونه زمان فاز GP در CPU ۱۰ نخی، ۱٫۱۰۶\% کاهش پیدا کرده است.



آموزش فاز LG هم بر روی CPU تک، ۱۰، ۲۰ و ۴۰ نخی برای چندیت طراحی مختلف منجمله \texttt{bigblue} انجام شده است که خروجی‌های زمانی آن در «شکل \رجوع{شکل:نمودار زمانی فاز LG بر بستر CPU}» آورده شده است. همانطور که مشخص است به طور میانگین این فاز بر روی CPU تک نخی زیر ۱ دقیقه طول می‌کشد.


\شروع{شکل}[ht]
\centerimg{img5.png}{12cm}
\شرح{نمودار زمانی فاز LG بر بستر CPU}
\برچسب{شکل:نمودار زمانی فاز LG بر بستر CPU}
\پایان{شکل}

همانطور که قبلا هم بیان شد، زمان اجرای این الگوریتم به صورت خطی با افزایش تعداد سلول ها زیاد می‌شود. «شکل \رجوع{شکل:تغییرات نمودار زمانی فاز GP}» نمودار رشد زمانی، با افزایش تعداد سلول ها را برای فاز GP نشان می‌دهد.

\شروع{شکل}[ht]
\centerimg{img6.png}{10cm}
\شرح{تغییرات نمودار زمانی فاز GP}
\برچسب{شکل:تغییرات نمودار زمانی فاز GP}
\پایان{شکل}


\قسمت{مزایا و معایب}

از مزایای روش پیشنهاد شده می‌توان به موارد زیر اشاره کرد:
\شروع{فقرات}
\فقره متن باز بودن آن
\فقره توسعه الگوریتم به دو زبان \texttt{Python} و \texttt{C++} 
\فقره توسعه الگوریتم بر دو بستر CPU و GPU
\فقره هماهنگ بودن با سایر الگوریتم های تحلیلی
\فقره سرعت بالای آن
\فقره عدم افت کیفیت طراحی
\فقره پشتیبانی\پاورقی{Affiliation} قوی پروژه که توسط شرکت NVIDIA انجام می‌شود.
\فقره و ...
\پایان{فقرات}

در کنار بیان مزایا می‌بایست به معایب پروژه را هم بیان کرد. در ادامه چند مورد از معایب پروژه انجام شده را بیان می‌کنیم:

\شروع{فقرات}
\فقره عدم اشاره مستقیم مقاله به ساختار شبکه‌عصبی استفاده شده
\فقره نیازمند بودن به سیستمی قوی برای اجرای این الگوریتم
\فقره عدم تست کردن الگوریتم با برچسب‌\texttt{Benchmark} های جدید تر مثل 2017 ISPD و 2018 ISPD
\فقره نیازمندی به پیشنیاز\پاورقی{Dependency} های مختلف
\فقره عدم صحبت از توان مصرفی الگوریتم
\فقره عدم ارائه گزارش از خطا‌های ناشی از اجرای الگوریتم
\فقره و ...
\پایان{فقرات}





\قسمت{اجرای عملی الگوریتم}

برای اجرای این الگوریتم بر روی سیستم شخصی می‌بایست مراحل زیر را طی کرد\زیرنویس{به دلیل استفاده اینجانب از سیستم‌عامل لینوکس، مراحلی که در ادامه نام برده شده است برای کاربران لینوکسی‌ست.}:

\زیرقسمت{نصب Git}
با دستور زیر می‌توان گیت را نصب نمود:
\begin{latin}
	\texttt{\textcolor{blue}{\$} sudo apt install git-all}
\end{latin}

همچنین با دستور زیر چک می‌کنیم که گیت به درستی نصب شده باشد:
\begin{latin}
	\texttt{\textcolor{blue}{\$} git --version}
\end{latin}

اگر در خروجی ورژن گیت برگشت داده شود، یعنی نصب به درستی انجام شده است:


\زیرقسمت{دانلود مخزن الگوریتم}

با استفاده از دستور زیر، مخزن\پاورقی{Repository} الگوریتم را دانلود می‌کنیم.
\begin{latin}
	\texttt{\textcolor{blue}{\$} git clone --recursive https://github.com/limbo018/DREAMPlace.git}
\end{latin}

پس از دانلود با دستور زیر به دایرکتوری فایل دانلود شده می‌رویم:
\begin{latin}
	\texttt{\textcolor{blue}{\$} cd DREAMPlace}
\end{latin}

\زیرقسمت{نصب پیش‌نیاز ها}
با دستور زیر، پیش‌نیاز ها\پاورقی{Dependency} ها را نصب می‌کنیم.
\begin{latin}
	\texttt{\textcolor{blue}{\$} pip install -r requirements.txt}
\end{latin}

\زیرقسمت{بیلد نرم‌افزار}
این نرم‌افزار را می‌توان به دو صورت بیلد کرد. استفاده از داکر\پاورقی{Docker} و یا بیلد معمولی بر روی سیستم\زیرنویس{در این گزارش بیلد معمولی بر روی سیستم را توضیح می‌دهیم. برای بیلد بر روی داکر می‌توانید \href{https://github.com/limbo018/DREAMPlace?tab=readme-ov-file}{اینجا} را ببینید.}.

\begin{latin}
	\texttt{\textcolor{blue}{\$} mkdir build}\\
	\texttt{\textcolor{blue}{\$} cd build \# we call this <build directory>}\\
	\texttt{\textcolor{blue}{\$} cmake .. -DCMAKE\_INSTALL\_PREFIX=<installation directory>}\\
	\texttt{-DPython\_EXECUTABLE=\$(which python)}\\
	\texttt{\textcolor{blue}{\$} make}\\
	\texttt{\textcolor{blue}{\$} make install}\\
\end{latin}

بیلد نرم‌افزار، مدتی طول خواهد کشید. اگر بیلد به درستی انجام شود، پیغام \texttt{Successful Building} نمایش داده می‌شود.

\زیرقسمت{انتخاب بنچ‌مارک}

با استفاده از دستور زیر می‌توان بنچ‌مارک مورد نظر را انتخاب کرد:

در این مقاله از بنچ‌مارک 2005 ISPD استفاده شده است.
\begin{latin}
	\texttt{\textcolor{blue}{\$} python benchmarks/ispd2005\_2015.py}
\end{latin}

\زیرقسمت{اجرای شبیه‌سازی}
پس از انتخاب بنچ‌مارک به صورت زیر می‌توان برنامه را اجرا کرد:
\begin{latin}
	\texttt{\textcolor{blue}{\$} cd <installation directory>}\\
	\texttt{\textcolor{blue}{\$} python unittest/ops/hpwl\_unittest.py}
\end{latin}