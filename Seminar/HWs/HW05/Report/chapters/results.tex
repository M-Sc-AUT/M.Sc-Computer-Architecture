
\فصل{چالش‌ها و نو‌آوری‌ها} \label{contrib}



\قسمت{تعریف دقیق مسئله}
یک سیستم از ابتدایی که شروع به کار می‌کند، تا زمانی که اولین علائم خرابی را از خود بروز می‌دهد، به‌صورت خطی کار می‌کند. پس از نمایان‌شدن اولین علامت خرابی می‌توان عمر سیستم را با یک تابع خطی با شیب ۱- مدل کرد \مرجع{heimes2008recurrent}. مدت زمانی که اولین زمان خرابی نمایان می‌شود تا زمانی که سیستم به طور کامل از کار بیفتد را عمر باقی‌مانده مفید می‌نامند. این زمان در سیستم‌های مختلف بسته به شرایط و کاربردهای آن متفاوت است؛ اما در اپلیکیشن مورد بررسی ما این زمان را می‌توان در بازه ۴ دقیقه تا ۱۲۴ دقیقه در نظر گرفت \مرجع{lu2021gan}. باتوجه‌به اینکه حداقل زمان ۴ دقیقه است، الزام وجود و استفاده از \lr{FPGA} خودش را نشان می‌دهد، زیرا می‌بایست تقریب و پیش‌بینی با بالاترین سرعت ممکن انجام شود و ازآنجاکه در خودروهای خودران نمی‌توان از پردازنده‌های گرافیکی استفاده کرد، می‌بایست از \lr{FPGA} استفاده نمود تا کمترین میزان توان مصرفی را با بالاترین سرعت پردازش داشته باشیم.










\قسمت{راه‌حل پیشنهادی و ایده‌ی اولیه}
همان‌طور که در بخش کار‌های پیشین «\رجوع{litreture}» مطرح شد، پژوهش‌های گسترده‌ای در این زمینه انجام شده است. اما تمامی کارای انجام شده صرفاً با دیدگاه نرم‌افزاری و آفلاین انجام شده است و پژوهش‌های کمی با این دیدگاه انجام شده است که پیش‌بینی به‌صورت آنلاین انجام شود. ما در این پژوهش قصد داریم با درنظرگرفتن کاربرد پیش‌بینی عمر باقی‌مانده بلبرینگ‌های خودروای خودران آن را بر روی \lr{FPGA} شبیه‌سازی و پیاده‌سازی آن را امکان‌سنجی کنیم. فاز آموزش شبکه ترنسفرمر به‌صورت نرم‌افزاری و بیرون از \lr{FPGA} انجام خواهد شد و شرایط محیطی تأثیرگذار در عمر بلبرینگ در نظر گرفته نمی‌شود. 



پیاده‌سازی‌های مختلفی از شبکه‌های \lr{Transformer} بر روی \lr{FPGA} انجام شده است و همگی آن‌ها به افزایش سرعت و کاهش انرژی مصرفی نسبت به \lr{GPU} و \lr{CPU} اشاره داشتند. برای مثال در \مرجع{chen2024understanding} فاز استنتاج\پانویس{Inference} شبکه‌های \lr{BERT} و \lr{GPT} بر روی \lr{FPGA} پیاده‌سازی شده است. در این مقاله گزارش شده است برای شبکه \lr{GPT}، سرعت ۹٫۱ و انرژی ۷٫۵ نسبت به پیاده‌سازی مشابه بر روی کارت گرافیک \lr{NVIDIA A100} بهبودیافته است.




در معماری شبکه \lr{Transformer} نیاز است که تمام داده‌ها به‌صورت کامل وارد شبکه شده و بتواند پیش‌بینی \lr{RUL} را انجام دهد. به عبارتی دیگر یعنی داده‌ای که در زمان $t_{n-10}$ وارد شبکه شده است بر داده‌ای که اکنون در زمان $t_n$ وارد شده است تأثیر می‌گذارد. این خود را زمانی نشان می‌دهد که بخواهیم این سیستم را بر روی \lr{FPGA} پیاده‌سازی کنیم. به دلیل آنکه در \lr{FPGA} حافظه بزرگی در اختیار نداریم نمی‌توانیم تمامی سیگنال را ذخیره کنیم و سپس پردازش را انجام دهیم و ازآنجایی‌که همه قسمت‌های سیگنال برای پیش‌بینی \lr{RUL} بادقت بالا مهم است، نمی‌توانیم بخش‌هایی از سیگنال را دور بریزیم تا با این روش محدودیت حافظه را دور بزنیم؛ زیرا ممکن است اطلاعات مهمی از تخریب سیگنال در آن نواحی باشد؛ بنابراین نیاز داریم مکانیزمی را پیشنهاد دهیم تا بتوانیم سیگنال را ذخیره و پردازش کنیم به‌نحوی‌که با محدودیت حافظه مواجه نشویم.




برای حل این چالش پیشنهاد می‌شود یک \lr{FIFO} در \lr{FPGA} در نظر گرفته شود که حجم آن بر اساس زمان پردازش سیستم تعیین می‌شود به‌طوری که در مدت زمانی که طول می‌کشد تا \lr{FIFO} پر شود، پردازش تکمیل شده باشد تا مجدداً \lr{FIFO} با داده جدید پر شود. با اعمال این تکنیک امید داریم تا بتوانیم تمام داده‌های ورودی را پردازش کنیم و داده‌ای از دست نرود. یکی دیگر از ضرورت‌های استفاده از \lr{FPGA} اینجا خودش را نشان می‌دهد، چرا که در پردازنده‌ها حجم \lr{FIFO} محدود است و نمی‌توانیم آن را متناسب با کاربرد خودمان تنظیم کنیم. حجم \lr{FIFO} بر اساس کاربرد تعیین می‌شود و این امکان را به ما می‌دهد که مناسب با نیازمان، \lr{FIFO} را تنظیم کنیم.

